{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37279d38",
   "metadata": {},
   "source": [
    "# Getting the general information only on the original webpage\n",
    "Output: a dataframe (table) of general information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea3d20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0                                                  1             2  \\\n",
      "0    436                             Addition of a Footpath      PL12 4EL   \n",
      "1    481                             Addition of a Footpath      PL30 5LP   \n",
      "2    539  Footpath upgrade to Bridleway status. Addition...       TR8 4HT   \n",
      "3    541  Addition of Footpath and Bridleway. Additional...      TR13 9TB   \n",
      "4    546                             Addition of a Footpath      PL24 2RR   \n",
      "5    547                             Addition of a Footpath      PL17 8DB   \n",
      "6    570           Deletion of  Vehicular Rights over Byway      PL34 OBE   \n",
      "7    583                     Addition a section of footpath       TR5 0SR   \n",
      "8    589  Footpath upgrade to Bridleway status. Addition...      PL26 7LT   \n",
      "9    590               Footpath upgrade to Bridleway status       TR2 4RG   \n",
      "10   593               Footpath upgrade to Bridleway status       TR2 4RE   \n",
      "11   623                              Addition of Bridleway      PL14 6HX   \n",
      "12   624  Addition of Byway Open to All Traffic and Foot...      PL10 1JB   \n",
      "13   633  Addition of Restricted Byway from Road A390 at...  Ivydene Farm   \n",
      "14   723  Addition of a Bridleway at Draynes Common, St ...      PL14 6QN   \n",
      "15   648                            Addition of a Bridleway      EX22 6TR   \n",
      "16   651       Addition of Footpaths and a Restricted Byway      TR19 7NX   \n",
      "17   697  Addition of a Bridleway at Hendra Down, Altarn...      PL15 7TL   \n",
      "18   195                            Addition of a Bridleway      TR16 5JF   \n",
      "19   412  Addition of a Footpath & Deletion of a Footpat...       TR2 5ES   \n",
      "20   524                             Addition of a Footpath      PL25 3NX   \n",
      "21   532                            Addition of  a Footpath      TR13 9SZ   \n",
      "22  531A                             Addition of a Footpath      TR16 4PF   \n",
      "23   542  Addition of Footpath and Bridleway. Additional...      TR13 9SZ   \n",
      "24   540                             Addition of a Footpath      TR19 6PR   \n",
      "25   550                             Addition of a Footpath      PL24 2LR   \n",
      "26   561                             Addition of a Footpath      PL11 3BQ   \n",
      "27   566                                 Addition of a BOAT      TR20 8XD   \n",
      "28   563                             Addition of a Footpath      TR27 5BE   \n",
      "29   554               Footpath upgrade to Bridleway status      PL30 3BP   \n",
      "\n",
      "                                            3               4  \\\n",
      "0                                     Saltash         Saltash   \n",
      "1                                     Withiel          Retire   \n",
      "2                        ColanSt Columb Major           Colan   \n",
      "3                                BreageGermoe   Tresowes Hill   \n",
      "4                                    Luxulyan      Ponts Mill   \n",
      "5                                    Calstock       Metherell   \n",
      "6                                    Tintagel        Tintagel   \n",
      "7                                    St Agnes        St Agnes   \n",
      "8                       St Stephen-In-Brannel          Coombe   \n",
      "9   Grampound With CreedSt Stephen-In-Brannel       Grampound   \n",
      "10  Grampound With CreedSt Stephen-In-Brannel       Grampound   \n",
      "11                                    St Neot         St Neot   \n",
      "12                            Maker-With-Rame       Millbrook   \n",
      "13                                     Kenwyn  Threemilestone   \n",
      "14                                    St Neot         St Neot   \n",
      "15                      Week St MaryWhitstone       Whitstone   \n",
      "16                                    St Just         St Just   \n",
      "17                                   Altarnun       Bolventor   \n",
      "18                              GwennapSt Day      Carharrack   \n",
      "19                        St Just-In-Roseland        St Mawes   \n",
      "20                             St Austell Bay     Charlestown   \n",
      "21                               BreageGermoe   Tresowes Hill   \n",
      "22                                  Portreath       Portreath   \n",
      "23                               BreageGermoe   Tresowes Hill   \n",
      "24                                   Penzance       Mousehole   \n",
      "25                                  St Blaise             Par   \n",
      "26                                   Sheviock       Crafthole   \n",
      "27                                     Madron         Ludgvan   \n",
      "28                                      Hayle           Hayle   \n",
      "29                                     St Kew        St Mabyn   \n",
      "\n",
      "                                            5                    6  \n",
      "0                                Saltash East   WCA 436 Details >>  \n",
      "1                        Lanivet And Blisland   WCA 481 Details >>  \n",
      "2          St Columb MajorSt Mawgan And Colan   WCA 539 Details >>  \n",
      "3                  Breage, Germoe and Sithney   WCA 541 Details >>  \n",
      "4                                       Bugle   WCA 546 Details >>  \n",
      "5    St Dominick, Harrowbarrow And Kelly Bray   WCA 547 Details >>  \n",
      "6                                    Tintagel   WCA 570 Details >>  \n",
      "7                                    St Agnes   WCA 583 Details >>  \n",
      "8                       St Stephen-In-Brannel   WCA 589 Details >>  \n",
      "9   St Stephen-In-BrannelSt Mewan & Grampound   WCA 590 Details >>  \n",
      "10  St Stephen-In-BrannelSt Mewan & Grampound   WCA 593 Details >>  \n",
      "11                                   St Cleer   WCA 623 Details >>  \n",
      "12                Rame Peninsula & St Germans   WCA 624 Details >>  \n",
      "13              Chacewater, Kenwyn And Baldhu   WCA 633 Details >>  \n",
      "14                                   St Cleer   WCA 723 Details >>  \n",
      "15                                 Poundstock   WCA 648 Details >>  \n",
      "16                         St Just In Penwith   WCA 651 Details >>  \n",
      "17                                   Altarnun   WCA 697 Details >>  \n",
      "18             Carharrack, Gwennap And St Day   WCA 195 Details >>  \n",
      "19            St Goran,Tregony & the Roseland   WCA 412 Details >>  \n",
      "20                             St Austell Bay   WCA 524 Details >>  \n",
      "21                 Breage, Germoe and Sithney   WCA 532 Details >>  \n",
      "22                  Mount Hawke And Portreath  WCA 531A Details >>  \n",
      "23                 Breage, Germoe and Sithney   WCA 542 Details >>  \n",
      "24              Mousehole, Newlyn & St Buryan   WCA 540 Details >>  \n",
      "25                                  St Blazey   WCA 550 Details >>  \n",
      "26                Rame Peninsula & St Germans   WCA 561 Details >>  \n",
      "27                                    Ludgvan   WCA 566 Details >>  \n",
      "28                                Hayle North   WCA 563 Details >>  \n",
      "29                            Wadebridge East   WCA 554 Details >>  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "start = 0\n",
    "num_pages = 37  # Set the desired number of pages to scrape\n",
    "\n",
    "all_rows = []  # List to store all the rows\n",
    "\n",
    "for page in range(num_pages):\n",
    "    url = f\"https://secure.cornwall.gov.uk/DMMO/Web/ModificationOrder/Index/Page/{start}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table element with class=\"table table-striped\"\n",
    "    table = soup.find('table', class_='table table-striped')\n",
    "\n",
    "    # Extract the table rows\n",
    "    rows = []\n",
    "    for tr in table.select('tbody tr'):\n",
    "        row_data = [td.get_text(strip=True) for td in tr.select('td')]\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # Add the rows to the main list\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "    # Increment the start value for the next iteration\n",
    "    start += 1\n",
    "\n",
    "    # Check if there are no more pages available\n",
    "    if \"No data available in table\" in soup.get_text():\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the rows\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5586f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239791ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in: downloads\\Cornwall.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create the downloads folder if it doesn't exist\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = os.path.join('downloads', 'Cornwall.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Print the file path for reference\n",
    "print(f\"CSV file saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0144d9",
   "metadata": {},
   "source": [
    "# Getting the general information only on the original webpage\n",
    "Output: a dataframe (table) of general information and a column of 'link' to sub-pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8bcd37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0                                                  1              2  \\\n",
      "0    436                             Addition of a Footpath       PL12 4EL   \n",
      "1    481                             Addition of a Footpath       PL30 5LP   \n",
      "2    539  Footpath upgrade to Bridleway status. Addition...        TR8 4HT   \n",
      "3    541  Addition of Footpath and Bridleway. Additional...       TR13 9TB   \n",
      "4    546                             Addition of a Footpath       PL24 2RR   \n",
      "..   ...                                                ...            ...   \n",
      "361  636  Addition of a Footpath from road U6003 to Foot...  Stile Cottage   \n",
      "362  654  Addition of a Bridleway & upgrade of a Footpat...       TR20 8RB   \n",
      "363  708       Deletion of Footpath at Trelash, Warbstow CP       PL15 8RL   \n",
      "364  743                       Addition of Restricted Byway       EX23 0BX   \n",
      "365  798  Addition of a Byway Open to All Traffic & Addi...       PL27 7UE   \n",
      "\n",
      "                        3              4                                   5  \\\n",
      "0                 Saltash        Saltash                        Saltash East   \n",
      "1                 Withiel         Retire                Lanivet And Blisland   \n",
      "2    ColanSt Columb Major          Colan  St Columb MajorSt Mawgan And Colan   \n",
      "3            BreageGermoe  Tresowes Hill          Breage, Germoe and Sithney   \n",
      "4                Luxulyan     Ponts Mill                               Bugle   \n",
      "..                    ...            ...                                 ...   \n",
      "361              Penzance       Penzance                Newlyn And Mousehole   \n",
      "362              Sancreed       Sancreed                          Land's End   \n",
      "363              Warbstow       Warbstow                            Tintagel   \n",
      "364             Jacobstow      Jacobstow                          Poundstock   \n",
      "365               St Eval        St Eval                             Padstow   \n",
      "\n",
      "                                           6  \n",
      "0      /DMMO/Web/ModificationOrder/Details/5  \n",
      "1     /DMMO/Web/ModificationOrder/Details/32  \n",
      "2     /DMMO/Web/ModificationOrder/Details/84  \n",
      "3     /DMMO/Web/ModificationOrder/Details/87  \n",
      "4     /DMMO/Web/ModificationOrder/Details/92  \n",
      "..                                       ...  \n",
      "361  /DMMO/Web/ModificationOrder/Details/203  \n",
      "362  /DMMO/Web/ModificationOrder/Details/228  \n",
      "363  /DMMO/Web/ModificationOrder/Details/294  \n",
      "364  /DMMO/Web/ModificationOrder/Details/338  \n",
      "365  /DMMO/Web/ModificationOrder/Details/402  \n",
      "\n",
      "[366 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "start = 0\n",
    "num_pages = 37  # Set the desired number of pages to scrape\n",
    "\n",
    "all_rows = []  # List to store all the rows\n",
    "\n",
    "for page in range(num_pages):\n",
    "    url = f\"https://secure.cornwall.gov.uk/DMMO/Web/ModificationOrder/Index/Page/{start}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table element with class=\"table table-striped\"\n",
    "    table = soup.find('table', class_='table table-striped')\n",
    "\n",
    "    # Extract the table rows\n",
    "    rows = []\n",
    "    for tr in table.select('tbody tr'):\n",
    "        row_data = [td.get_text(strip=True) if td.find('a') is None else td.a['href'] for td in tr.select('td')]\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # Add the rows to the main list\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "    # Increment the start value for the next iteration\n",
    "    start += 1\n",
    "\n",
    "    # Check if there are no more pages available\n",
    "    if \"No data available in table\" in soup.get_text():\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the rows\n",
    "df1 = pd.DataFrame(all_rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce1f74",
   "metadata": {},
   "source": [
    "## save the scraped ouput to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5706c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in: downloads\\Cornwall1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create the downloads folder if it doesn't exist\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = os.path.join('downloads', 'Cornwall1.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "df1.to_csv(file_path, index=False)\n",
    "\n",
    "# Print the file path for reference\n",
    "print(f\"CSV file saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f490e",
   "metadata": {},
   "source": [
    "# Getting the information in main page and sub-pages\n",
    "Output: a dataframe (table) of information shown on main page and sub-pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9dda663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WCA Ref                              Effect of Application       Postcode  \\\n",
      "0       436                             Addition of a Footpath       PL12 4EL   \n",
      "1       481                             Addition of a Footpath       PL30 5LP   \n",
      "2       539  Footpath upgrade to Bridleway status. Addition...        TR8 4HT   \n",
      "3       541  Addition of Footpath and Bridleway. Additional...       TR13 9TB   \n",
      "4       546                             Addition of a Footpath       PL24 2RR   \n",
      "..      ...                                                ...            ...   \n",
      "361     636  Addition of a Footpath from road U6003 to Foot...  Stile Cottage   \n",
      "362     654  Addition of a Bridleway & upgrade of a Footpat...       TR20 8RB   \n",
      "363     708       Deletion of Footpath at Trelash, Warbstow CP       PL15 8RL   \n",
      "364     743                       Addition of Restricted Byway       EX23 0BX   \n",
      "365     798  Addition of a Byway Open to All Traffic & Addi...       PL27 7UE   \n",
      "\n",
      "                Parish/es City/Town/Village  \\\n",
      "0                 Saltash           Saltash   \n",
      "1                 Withiel            Retire   \n",
      "2    ColanSt Columb Major             Colan   \n",
      "3            BreageGermoe     Tresowes Hill   \n",
      "4                Luxulyan        Ponts Mill   \n",
      "..                    ...               ...   \n",
      "361              Penzance          Penzance   \n",
      "362              Sancreed          Sancreed   \n",
      "363              Warbstow          Warbstow   \n",
      "364             Jacobstow         Jacobstow   \n",
      "365               St Eval           St Eval   \n",
      "\n",
      "                   Electoral Division/s  \\\n",
      "0                          Saltash East   \n",
      "1                  Lanivet And Blisland   \n",
      "2    St Columb MajorSt Mawgan And Colan   \n",
      "3            Breage, Germoe and Sithney   \n",
      "4                                 Bugle   \n",
      "..                                  ...   \n",
      "361                Newlyn And Mousehole   \n",
      "362                          Land's End   \n",
      "363                            Tintagel   \n",
      "364                          Poundstock   \n",
      "365                             Padstow   \n",
      "\n",
      "                                     Details Date of Application  \\\n",
      "0      /DMMO/Web/ModificationOrder/Details/5          19/09/2001   \n",
      "1     /DMMO/Web/ModificationOrder/Details/32          19/03/2003   \n",
      "2     /DMMO/Web/ModificationOrder/Details/84          21/06/2006   \n",
      "3     /DMMO/Web/ModificationOrder/Details/87          18/12/2006   \n",
      "4     /DMMO/Web/ModificationOrder/Details/92          08/11/2007   \n",
      "..                                       ...                 ...   \n",
      "361  /DMMO/Web/ModificationOrder/Details/203          19/03/2018   \n",
      "362  /DMMO/Web/ModificationOrder/Details/228          12/01/2019   \n",
      "363  /DMMO/Web/ModificationOrder/Details/294          18/10/2019   \n",
      "364  /DMMO/Web/ModificationOrder/Details/338          20/02/2020   \n",
      "365  /DMMO/Web/ModificationOrder/Details/402          04/06/2022   \n",
      "\n",
      "    Direction - Secretary of State Determination Date Determination Decision  \\\n",
      "0            Directed to determine         06/09/2017          Make an order   \n",
      "1                       No Request         06/09/2017          Make an order   \n",
      "2            Directed to determine         14/08/2018          Make an order   \n",
      "3            Directed to determine         05/03/2019          Make an order   \n",
      "4                       No Request                        Not yet determined   \n",
      "..                             ...                ...                    ...   \n",
      "361          Directed to determine         16/06/2021      Not make an order   \n",
      "362          Directed to determine         11/11/2022          Make an order   \n",
      "363                     No Request                        Not yet determined   \n",
      "364                     No Request                        Not yet determined   \n",
      "365                     No Request                        Not yet determined   \n",
      "\n",
      "                                        Applicant Name  \\\n",
      "0                                 Saltash Town Council   \n",
      "1                                  P Cardew & R Renouf   \n",
      "2                                British Horse Society   \n",
      "3               Breage & Germoe Bridleways Association   \n",
      "4                       The Friends of Luxulyan Valley   \n",
      "..                                                 ...   \n",
      "361                                        Peter Perry   \n",
      "362  Kenneth Sharp, Ramblers & West Penwith Bridlew...   \n",
      "363                                        Mr G Hawken   \n",
      "364                                          Mr A BIgg   \n",
      "365                                        Mr R Fraser   \n",
      "\n",
      "                                     Applicant Address Applicant Postcode  \\\n",
      "0        The Guildhall, 12, Lower Fore Street, Saltash           PL12 6JX   \n",
      "1    Tremore Valley House, Tremore Valley, Withiel,...           PL30 5LS   \n",
      "2          Mrs J Combes, An Hewas, Gusti Veor, Newquay            TR8 4JU   \n",
      "3           Chymunys, Tregonning Lane, Breage, Helston           TR13 9QU   \n",
      "4                    Penrose Cottage, Luxulyan, Bodmin           PL30 5EQ   \n",
      "..                                                 ...                ...   \n",
      "361          Stile Cottage, Trevithal, Paul, Penzance,           TR19 6UQ   \n",
      "362    Higher Kerris Farmhouse, Kerris, Paul, Penzance           TR19 6UY   \n",
      "363      Penwenham Farm, Trelash, Warbstow, Launceston           PL15 8RL   \n",
      "364               Trevessa Farm,Trevega,Zennor,St Ives           TR26 3BL   \n",
      "365                   Shenavall, Tremoughdale, Penryn,           TR10 8JA   \n",
      "\n",
      "                                  Additional Documents  \n",
      "0    https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "1    https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "2    https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "3    https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "4    https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "..                                                 ...  \n",
      "361  https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "362  https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "363  https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "364  https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "365  https://secure.cornwall.gov.uk/DMMO/Web/Modifi...  \n",
      "\n",
      "[366 rows x 15 columns]\n",
      "Runtime: 61.34790658950806 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "start = 0\n",
    "num_pages = 37  # Set the desired number of pages to scrape\n",
    "\n",
    "all_rows = []  # List to store all the rows\n",
    "\n",
    "for page in range(num_pages):\n",
    "    url = f\"https://secure.cornwall.gov.uk/DMMO/Web/ModificationOrder/Index/Page/{start}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table element with class=\"table table-striped\"\n",
    "    table = soup.find('table', class_='table table-striped')\n",
    "\n",
    "    # Extract the table rows\n",
    "    rows = []\n",
    "    for tr in table.select('tbody tr'):\n",
    "        row_data = [td.get_text(strip=True) if td.find('a') is None else td.a['href'] for td in tr.select('td')]\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # Add the rows to the main list\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "    # Increment the start value for the next iteration\n",
    "    start += 1\n",
    "\n",
    "    # Check if there are no more pages available\n",
    "    if \"No data available in table\" in soup.get_text():\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the rows\n",
    "df1 = pd.DataFrame(all_rows, columns=[\"WCA Ref\", \"Effect of Application\", \"Postcode\", \"Parish/es\", \"City/Town/Village\", \"Electoral Division/s\", \"Details\"])\n",
    "\n",
    "# Scrape the details page for each row\n",
    "for index, row in df1.iterrows():\n",
    "    details_url = \"https://secure.cornwall.gov.uk\" + row[\"Details\"]\n",
    "    details_response = requests.get(details_url)\n",
    "    details_soup = BeautifulSoup(details_response.content, 'html.parser')\n",
    "\n",
    "    # Extract the desired information from the details page\n",
    "    applicant_name = details_soup.find('div', class_='tab-pane', id='tabApplicant').find('div', class_='controls').get_text(strip=True)\n",
    "    applicant_address = details_soup.find('div', class_='tab-pane', id='tabApplicant').find('div', class_='controls').find_next('div', class_='controls').get_text(strip=True)\n",
    "    applicant_postcode = details_soup.find('div', class_='tab-pane', id='tabApplicant').find('div', class_='controls').find_next('div', class_='controls').find_next('div', class_='controls').get_text(strip=True)\n",
    "\n",
    "    additional_documents = details_soup.find('div', class_='tab-pane', id='tabFiles').find('div', class_='control-group').find_next('div', class_='control-group').find('a', class_='uline')['href']\n",
    "    additional_documents = \"https://secure.cornwall.gov.uk\" + additional_documents\n",
    "    \n",
    "    # Extract the additional information from the details page\n",
    "    details_div = details_soup.find('div', class_='tab-pane', id='tabDetails')\n",
    "    if details_div:\n",
    "        wca_ref = details_div.find('label', text='WCA Ref').find_next('div', class_='controls').get_text(strip=True)\n",
    "        date_of_application = details_div.find('label', text='Date of Application').find_next('div', class_='controls').get_text(strip=True)\n",
    "        effect_of_application = details_div.find('label', text='Effect of Application').find_next('div', class_='controls').get_text(strip=True)\n",
    "        target_date = details_div.find('label', text='Target Date').find_next('div', class_='controls').get_text(strip=True)\n",
    "        direction = details_div.find('label', text='Direction - Secretary of State').find_next('div', class_='controls').get_text(strip=True)\n",
    "        determination_date = details_div.find('label', text='Determination Date').find_next('div', class_='controls').get_text(strip=True)\n",
    "        determination_decision = details_div.find('label', text='Determination Decision').find_next('div', class_='controls').get_text(strip=True)\n",
    "\n",
    "# Update the corresponding columns in the DataFrame\n",
    "    df1.at[index, \"Date of Application\"] = date_of_application\n",
    "    df1.at[index, \"Direction - Secretary of State\"] = direction\n",
    "    df1.at[index, \"Determination Date\"] = determination_date\n",
    "    df1.at[index, \"Determination Decision\"] = determination_decision\n",
    "\n",
    "    # Update the corresponding columns in the DataFrame\n",
    "    df1.at[index, \"Applicant Name\"] = applicant_name\n",
    "    df1.at[index, \"Applicant Address\"] = applicant_address\n",
    "    df1.at[index, \"Applicant Postcode\"] = applicant_postcode\n",
    "    df1.at[index, \"Additional Documents\"] = additional_documents\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df1)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "# Calculate the runtime\n",
    "runtime = end_time - start_time\n",
    "# Display the runtime\n",
    "print(\"Runtime:\", runtime, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db832b",
   "metadata": {},
   "source": [
    "## save the scraped ouput to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40564cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in: downloads\\Cornwall_details.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create the downloads folder if it doesn't exist\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = os.path.join('downloads', 'Cornwall_details.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "df1.to_csv(file_path, index=False)\n",
    "\n",
    "# Print the file path for reference\n",
    "print(f\"CSV file saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1c2c2",
   "metadata": {},
   "source": [
    "# simply putting information in tables and save to local\n",
    "In the following example, the 'new_data' was first obtained by GPT-4 plugin Link Reader\n",
    "The prompt line I used in Link Reader was:\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/CDB.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/ADA.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/CDC.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/ADB.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/ADC.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/ADD.pdf\n",
    "https://buckinghamshire-gov-uk.s3.amazonaws.com/documents/BAT.pdf\n",
    "Read the pdf and includes File Reference, Grid Ref Start, Grid Ref End, Committee Decision, Committee Decision Date, Organisation, Date of Application, Parish, put into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3793d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File Reference Grid Ref Start   Grid Ref End Committee Decision  \\\n",
      "0      16855 CDB  SU78550-07033  SU78105-06435   To be determined   \n",
      "1      16855 ADA  SP76513-09715  SP76044-10273   To be determined   \n",
      "2      16855 CDC  SU92608-92926  SU92224-92705   To be determined   \n",
      "3      16855 ADB    SU9015-9868    SU9065-9741   To be determined   \n",
      "\n",
      "  Committee Decision Date Organisation Date of Application  \\\n",
      "0        To be determined          N/A          21/09/2022   \n",
      "1        To be determined          N/A          18/04/2023   \n",
      "2        To be determined          N/A          28/03/2023   \n",
      "3        To be determined          N/A          07/03/2020   \n",
      "\n",
      "                       Parish  \n",
      "0          Longwick-cum-Ilmer  \n",
      "1  Dinton with Ford and Upton  \n",
      "2                        Penn  \n",
      "3                        Penn  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_data = [\n",
    "    {\n",
    "        'File Reference': '16855 CDB',\n",
    "        'Grid Ref Start': 'SU78550-07033',\n",
    "        'Grid Ref End': 'SU78105-06435',\n",
    "        'Committee Decision': 'To be determined',\n",
    "        'Committee Decision Date': 'To be determined',\n",
    "        'Organisation': 'N/A',\n",
    "        'Date of Application': '21/09/2022',\n",
    "        'Parish': 'Longwick-cum-Ilmer'\n",
    "    },\n",
    "    {\n",
    "        'File Reference': '16855 ADA',\n",
    "        'Grid Ref Start': 'SP76513-09715',\n",
    "        'Grid Ref End': 'SP76044-10273',\n",
    "        'Committee Decision': 'To be determined',\n",
    "        'Committee Decision Date': 'To be determined',\n",
    "        'Organisation': 'N/A',\n",
    "        'Date of Application': '18/04/2023',\n",
    "        'Parish': 'Dinton with Ford and Upton'\n",
    "    },\n",
    "    {\n",
    "        'File Reference': '16855 CDC',\n",
    "        'Grid Ref Start': 'SU92608-92926',\n",
    "        'Grid Ref End': 'SU92224-92705',\n",
    "        'Committee Decision': 'To be determined',\n",
    "        'Committee Decision Date': 'To be determined',\n",
    "        'Organisation': 'N/A',\n",
    "        'Date of Application': '28/03/2023',\n",
    "        'Parish': 'Penn'\n",
    "    },\n",
    "    {\n",
    "        'File Reference': '16855 ADB',\n",
    "        'Grid Ref Start': 'SU9015-9868',\n",
    "        'Grid Ref End': 'SU9065-9741',\n",
    "        'Committee Decision': 'To be determined',\n",
    "        'Committee Decision Date': 'To be determined',\n",
    "        'Organisation': 'N/A',\n",
    "        'Date of Application': '07/03/2020',\n",
    "        'Parish': 'Penn'\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(new_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb6de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved in: downloads\\dff.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create the downloads folder if it doesn't exist\n",
    "os.makedirs('downloads', exist_ok=True)\n",
    "\n",
    "# Define the file path for the CSV file (I used my 'downloads' here but this depends on the author's computer)\n",
    "file_path = os.path.join('downloads', 'dff.csv')\n",
    "\n",
    "# Save the DataFrame to the CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Print the file path for reference\n",
    "print(f\"CSV file saved in: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cd04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
